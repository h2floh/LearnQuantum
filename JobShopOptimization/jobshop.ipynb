{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code C9NUVT49H to authenticate.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<msrest.authentication.BasicTokenAuthentication at 0x7fe6c9b6d690>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from typing import List\n",
    "from azure.quantum.optimization import Term\n",
    "from azure.quantum import Workspace\n",
    "\n",
    "workspace = Workspace (\n",
    "    subscription_id = \"\",  # Add your subscription_id\n",
    "    resource_group = \"\",   # Add your resource_group\n",
    "    name = \"\",             # Add your workspace name\n",
    "    location = \"\"          # Add your workspace location (for example, \"westus\")\n",
    "    )\n",
    "\n",
    "workspace.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(jobs_ops_map:dict, machines_ops_map:dict, processing_time:dict, T:int):\n",
    "    \"\"\"\n",
    "    Process & validate problem parameters (config) and generate inverse dict of operations to jobs.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    machines_ops_map(dict): Mapping of operations to machines, e.g.:\n",
    "        machines_ops_map = {\n",
    "            0: [0,1],          # Operations 0 & 1 assigned to machine 0\n",
    "            1: [2,3]           # Operations 2 & 3 assigned to machine 1\n",
    "        }\n",
    "    processing_time (dict): Operation processing times\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    \"\"\"\n",
    "\n",
    "    # Problem cannot take longer to complete than all operations executed sequentially\n",
    "    ## Sum all operation processing times to calculate the maximum makespan\n",
    "    T = min(sum(processing_time.values()), T) \n",
    "\n",
    "    # Ensure operation assignments to machines are sorted in ascending order\n",
    "    for m, ops in machines_ops_map.items():\n",
    "        machines_ops_map[m] = sorted(ops)\n",
    "    ops_jobs_map = {}\n",
    "\n",
    "    for job, ops in jobs_ops_map.items():\n",
    "        # Fail if operation IDs within a job are out of order\n",
    "        assert (ops == sorted(ops)), f\"Operation IDs within a job must be in ascending order. Job was: {job}: {ops}\"\n",
    "\n",
    "        for op in ops:\n",
    "            # Fail if there are duplicate operation IDs\n",
    "            assert (op not in ops_jobs_map.keys()), f\"Operation IDs must be unique. Duplicate ID was: {op}\"\n",
    "            ops_jobs_map[op] = job\n",
    "\n",
    "    return ops_jobs_map, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set problem parameters\n",
    "## Allowed time (jobs can only be scheduled below this limit)\n",
    "T = 10\n",
    "\n",
    "## Processing time for each operation\n",
    "processing_time = {0: 2, 1: 1, 2: 2, 3: 2, 4: 1, 5: 2}\n",
    "\n",
    "## Assignment of operations to jobs (job ID: [operation IDs])\n",
    "### Operation IDs within a job must be in ascending order\n",
    "jobs_ops_map = {\n",
    "    0: [0, 1], # Restart life support\n",
    "    1: [2, 3], # Recalibrate navigation system\n",
    "    2: [4, 5]  # Replace power transformer in the reactor\n",
    "}\n",
    "\n",
    "## Assignment of operations to machines\n",
    "### Three jobs, two machines\n",
    "machines_ops_map = {\n",
    "    0: [0, 1, 4, 5], # Operations 0, 1, 4 and 5 are assigned to machine 0 (the universal multi-tool)\n",
    "    1: [2, 3]        # Operations 2 & 3 are assigned to machine 1 (the ship computer)\n",
    "}\n",
    "\n",
    "## Inverse mapping of jobs to operations\n",
    "ops_jobs_map, T = process_config(jobs_ops_map, machines_ops_map, processing_time, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precedence_constraint(jobs_ops_map:dict, T:int, processing_time:dict, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the precedence constraint.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # Loop through all jobs:\n",
    "    for ops in jobs_ops_map.values():\n",
    "        # Loop through all operations in this job:\n",
    "        for i in range(len(ops) - 1):\n",
    "            for t in range(0, T):\n",
    "                # Loop over times that would violate the constraint:\n",
    "                for s in range(0, min(t + processing_time[ops[i]], T)):\n",
    "                    # Assign penalty\n",
    "                    terms.append(Term(c=weight, indices=[ops[i]*T+t, (ops[i+1])*T+s]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation_once_constraint(ops_jobs_map:dict, T:int, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the operation once constraint.\n",
    "    Penalty function is of form: 2xy - x - y + 1\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    ops_jobs_map (dict): Map of operations to jobs {op: job}\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # 2xy - x - y parts of the constraint function\n",
    "    # Loop through all operations\n",
    "    for op in ops_jobs_map.keys():\n",
    "        for t in range(T):\n",
    "            # - x - y terms\n",
    "            terms.append(Term(c=weight*-1, indices=[op*T+t]))\n",
    "\n",
    "            # + 2xy term\n",
    "            # Loop through all other start times for the same job\n",
    "            # to get the cross terms\n",
    "            for s in range(t+1, T):\n",
    "                terms.append(Term(c=weight*2, indices=[op*T+t, op*T+s]))\n",
    "\n",
    "    # + 1 term\n",
    "    terms.append(Term(c=weight*1, indices=[]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_overlap_constraint(T:int, processing_time:dict, ops_jobs_map:dict, machines_ops_map:dict, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the no overlap constraint.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    weight (float): Relative importance of this constraint\n",
    "    ops_jobs_map (dict): Map of operations to jobs {op: job}\n",
    "    machines_ops_map(dict): Mapping of operations to machines, e.g.:\n",
    "        machines_ops_map = {\n",
    "            0: [0,1],          # Operations 0 & 1 assigned to machine 0\n",
    "            1: [2,3]           # Operations 2 & 3 assigned to machine 1\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # For each machine\n",
    "    for ops in machines_ops_map.values():\n",
    "        # Loop over each operation i requiring this machine\n",
    "        for i in ops:\n",
    "            # Loop over each operation k requiring this machine \n",
    "            for k in ops:\n",
    "                # Loop over simulation time\n",
    "                for t in range(T):\n",
    "                    # When i != k (when scheduling two different operations)\n",
    "                    if i != k:\n",
    "                        # t = s meaning two operations are scheduled to start at the same time on the same machine\n",
    "                        terms.append(Term(c=weight*1, indices=[i*T+t, k*T+t]))\n",
    "\n",
    "                        # Add penalty when operation runtimes overlap\n",
    "                        for s in range(t, min(t + processing_time[i], T)):\n",
    "                            terms.append(Term(c=weight*1, indices=[i*T+t, k*T+s]))  \n",
    "\n",
    "                        # If operations are in the same job, penalize for the extra time 0 -> t (operations scheduled out of order)\n",
    "                        if ops_jobs_map[i] == ops_jobs_map[k]:\n",
    "                            for s in range(0, t):\n",
    "                                if i < k:\n",
    "                                    terms.append(Term(c=weight*1, indices=[i*T+t, k*T+s]))  \n",
    "                                if i > k:\n",
    "                                    terms.append(Term(c=weight*1, indices=[i*T+s, k*T+t]))  \n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_penalty(t:int, m_count:int, t0:int): \n",
    "    assert m_count > 1                           # Ensure you don't divide by 0\n",
    "    return (m_count**(t - t0) - 1)/float(m_count - 1)\n",
    "\n",
    "def makespan_objective(T:int, processing_time:dict, jobs_ops_map:dict, m_count:int, weight:float):\n",
    "    \"\"\"\n",
    "    Construct makespan minimization terms.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    m_count (int): Number of machines\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    lower_bound = max([sum([processing_time[i] for i in job]) for job in jobs_ops_map.values()])\n",
    "    upper_bound = T\n",
    "\n",
    "    # Loop through the final operation of each job\n",
    "    for job in jobs_ops_map.values():\n",
    "        i = job[-1]\n",
    "        # Loop through each time step the operation could be completion at\n",
    "        for t in range(lower_bound + 1, T + processing_time[i]):\n",
    "            terms.append(Term(c=weight*(calc_penalty(t, m_count, lower_bound)), indices=[i*T + (t - processing_time[i])]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'jobs_ops_map' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9cbdb7662ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m## Build terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m### Constraints:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecedence_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs_ops_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperation_once_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops_jobs_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_overlap_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops_jobs_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmachines_ops_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jobs_ops_map' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate terms to submit to solver using functions defined previously\n",
    "## Assign penalty term weights:\n",
    "alpha = 5  # Precedence constraint\n",
    "beta = 5   # Operation once constraint\n",
    "gamma = 5  # No overlap constraint\n",
    "delta = 0.004  # Makespan minimization (objective function)\n",
    "\n",
    "## Build terms\n",
    "### Constraints:\n",
    "c1 = precedence_constraint(jobs_ops_map, T, processing_time, alpha)\n",
    "c2 = operation_once_constraint(ops_jobs_map, T, beta)\n",
    "c3 = no_overlap_constraint(T, processing_time, ops_jobs_map, machines_ops_map, gamma)\n",
    "\n",
    "### Objective function\n",
    "c4 = makespan_objective(T, processing_time, jobs_ops_map, len(machines_ops_map), delta)\n",
    "\n",
    "### Combine terms:\n",
    "terms = []\n",
    "terms = c1 + c2 + c3 + c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'azure.quantum' has no attribute 'storage'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bb84a67aea57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run job synchronously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'configuration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/azure/quantum/optimization/solvers.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mProblem\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Submitted job: '{job.id}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/azure/quantum/optimization/solvers.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mcontainer_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContainerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_container_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mcreate_container_using_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mcontainer_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mazure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_sas_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Storage account is passed, use it to generate a container_uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'azure.quantum' has no attribute 'storage'"
     ]
    }
   ],
   "source": [
    "from azure.quantum.optimization import Problem, ProblemType\n",
    "from azure.quantum.optimization import SimulatedAnnealing # Change this line to match the Azure Quantum Optimization solver type you wish to use\n",
    "\n",
    "# Problem type is PUBO in this instance. You could also have chosen to represent the problem in Ising form.\n",
    "problem = Problem(name=\"Job shop sample\", problem_type=ProblemType.pubo, terms=terms)\n",
    "\n",
    "# Provide details of your workspace, created at the beginning of this tutorial\n",
    "# Provide the name of the solver you wish to use for this problem (as imported above)\n",
    "solver = SimulatedAnnealing(workspace, timeout = 100) # Timeout in seconds\n",
    "\n",
    "# Run job synchronously\n",
    "result = solver.optimize(problem)\n",
    "config = result['configuration']\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}