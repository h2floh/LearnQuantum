{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from azure.quantum.optimization import Term\n",
    "from azure.quantum import Workspace\n",
    "\n",
    "workspace = Workspace(\n",
    "    subscription_id = \"\",  # Add your subscription_id\n",
    "    resource_group = \"\",   # Add your resource_group\n",
    "    name = \"\",             # Add your workspace name\n",
    "    location = \"\"          # Add your workspace location (for example, \"westus\")\n",
    ")\n",
    "\n",
    "workspace.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(jobs_ops_map:dict, machines_ops_map:dict, processing_time:dict, T:int):\n",
    "    \"\"\"\n",
    "    Process & validate problem parameters (config) and generate inverse dict of operations to jobs.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    machines_ops_map(dict): Mapping of operations to machines, e.g.:\n",
    "        machines_ops_map = {\n",
    "            0: [0,1],          # Operations 0 & 1 assigned to machine 0\n",
    "            1: [2,3]           # Operations 2 & 3 assigned to machine 1\n",
    "        }\n",
    "    processing_time (dict): Operation processing times\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    \"\"\"\n",
    "\n",
    "    # Problem cannot take longer to complete than all operations executed sequentially\n",
    "    ## Sum all operation processing times to calculate the maximum makespan\n",
    "    T = min(sum(processing_time.values()), T) \n",
    "\n",
    "    # Ensure operation assignments to machines are sorted in ascending order\n",
    "    for m, ops in machines_ops_map.items():\n",
    "        machines_ops_map[m] = sorted(ops)\n",
    "    ops_jobs_map = {}\n",
    "\n",
    "    for job, ops in jobs_ops_map.items():\n",
    "        # Fail if operation IDs within a job are out of order\n",
    "        assert (ops == sorted(ops)), f\"Operation IDs within a job must be in ascending order. Job was: {job}: {ops}\"\n",
    "\n",
    "        for op in ops:\n",
    "            # Fail if there are duplicate operation IDs\n",
    "            assert (op not in ops_jobs_map.keys()), f\"Operation IDs must be unique. Duplicate ID was: {op}\"\n",
    "            ops_jobs_map[op] = job\n",
    "\n",
    "    return ops_jobs_map, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set problem parameters\n",
    "## Allowed time (jobs can only be scheduled below this limit)\n",
    "T = 10\n",
    "\n",
    "## Processing time for each operation\n",
    "processing_time = {0: 2, 1: 1, 2: 2, 3: 2, 4: 1, 5: 2}\n",
    "\n",
    "## Assignment of operations to jobs (job ID: [operation IDs])\n",
    "### Operation IDs within a job must be in ascending order\n",
    "jobs_ops_map = {\n",
    "    0: [0, 1], # Restart life support\n",
    "    1: [2, 3], # Recalibrate navigation system\n",
    "    2: [4, 5]  # Replace power transformer in the reactor\n",
    "}\n",
    "\n",
    "## Assignment of operations to machines\n",
    "### Three jobs, two machines\n",
    "machines_ops_map = {\n",
    "    0: [0, 1, 4, 5], # Operations 0, 1, 4 and 5 are assigned to machine 0 (the universal multi-tool)\n",
    "    1: [2, 3]        # Operations 2 & 3 are assigned to machine 1 (the ship computer)\n",
    "}\n",
    "\n",
    "## Inverse mapping of jobs to operations\n",
    "ops_jobs_map, T = process_config(jobs_ops_map, machines_ops_map, processing_time, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precedence_constraint(jobs_ops_map:dict, T:int, processing_time:dict, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the precedence constraint.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # Loop through all jobs:\n",
    "    for ops in jobs_ops_map.values():\n",
    "        # Loop through all operations in this job:\n",
    "        for i in range(len(ops) - 1):\n",
    "            for t in range(0, T):\n",
    "                # Loop over times that would violate the constraint:\n",
    "                for s in range(0, min(t + processing_time[ops[i]], T)):\n",
    "                    # Assign penalty\n",
    "                    terms.append(Term(c=weight, indices=[ops[i]*T+t, (ops[i+1])*T+s]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation_once_constraint(ops_jobs_map:dict, T:int, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the operation once constraint.\n",
    "    Penalty function is of form: 2xy - x - y + 1\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    ops_jobs_map (dict): Map of operations to jobs {op: job}\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # 2xy - x - y parts of the constraint function\n",
    "    # Loop through all operations\n",
    "    for op in ops_jobs_map.keys():\n",
    "        for t in range(T):\n",
    "            # - x - y terms\n",
    "            terms.append(Term(c=weight*-1, indices=[op*T+t]))\n",
    "\n",
    "            # + 2xy term\n",
    "            # Loop through all other start times for the same job\n",
    "            # to get the cross terms\n",
    "            for s in range(t+1, T):\n",
    "                terms.append(Term(c=weight*2, indices=[op*T+t, op*T+s]))\n",
    "\n",
    "    # + 1 term\n",
    "    terms.append(Term(c=weight*1, indices=[]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_overlap_constraint(T:int, processing_time:dict, ops_jobs_map:dict, machines_ops_map:dict, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the no overlap constraint.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    weight (float): Relative importance of this constraint\n",
    "    ops_jobs_map (dict): Map of operations to jobs {op: job}\n",
    "    machines_ops_map(dict): Mapping of operations to machines, e.g.:\n",
    "        machines_ops_map = {\n",
    "            0: [0,1],          # Operations 0 & 1 assigned to machine 0\n",
    "            1: [2,3]           # Operations 2 & 3 assigned to machine 1\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # For each machine\n",
    "    for ops in machines_ops_map.values():\n",
    "        # Loop over each operation i requiring this machine\n",
    "        for i in ops:\n",
    "            # Loop over each operation k requiring this machine \n",
    "            for k in ops:\n",
    "                # Loop over simulation time\n",
    "                for t in range(T):\n",
    "                    # When i != k (when scheduling two different operations)\n",
    "                    if i != k:\n",
    "                        # t = s meaning two operations are scheduled to start at the same time on the same machine\n",
    "                        terms.append(Term(c=weight*1, indices=[i*T+t, k*T+t]))\n",
    "\n",
    "                        # Add penalty when operation runtimes overlap\n",
    "                        for s in range(t, min(t + processing_time[i], T)):\n",
    "                            terms.append(Term(c=weight*1, indices=[i*T+t, k*T+s]))  \n",
    "\n",
    "                        # If operations are in the same job, penalize for the extra time 0 -> t (operations scheduled out of order)\n",
    "                        if ops_jobs_map[i] == ops_jobs_map[k]:\n",
    "                            for s in range(0, t):\n",
    "                                if i < k:\n",
    "                                    terms.append(Term(c=weight*1, indices=[i*T+t, k*T+s]))  \n",
    "                                if i > k:\n",
    "                                    terms.append(Term(c=weight*1, indices=[i*T+s, k*T+t]))  \n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_penalty(t:int, m_count:int, t0:int): \n",
    "    assert m_count > 1                           # Ensure you don't divide by 0\n",
    "    return (m_count**(t - t0) - 1)/float(m_count - 1)\n",
    "\n",
    "def makespan_objective(T:int, processing_time:dict, jobs_ops_map:dict, m_count:int, weight:float):\n",
    "    \"\"\"\n",
    "    Construct makespan minimization terms.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    m_count (int): Number of machines\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    lower_bound = max([sum([processing_time[i] for i in job]) for job in jobs_ops_map.values()])\n",
    "    upper_bound = T\n",
    "\n",
    "    # Loop through the final operation of each job\n",
    "    for job in jobs_ops_map.values():\n",
    "        i = job[-1]\n",
    "        # Loop through each time step the operation could be completion at\n",
    "        for t in range(lower_bound + 1, T + processing_time[i]):\n",
    "            terms.append(Term(c=weight*(calc_penalty(t, m_count, lower_bound)), indices=[i*T + (t - processing_time[i])]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate terms to submit to solver using functions defined previously\n",
    "## Assign penalty term weights:\n",
    "alpha = 5  # Precedence constraint\n",
    "beta = 5   # Operation once constraint\n",
    "gamma = 5  # No overlap constraint\n",
    "delta = 0.004  # Makespan minimization (objective function)\n",
    "\n",
    "## Build terms\n",
    "### Constraints:\n",
    "c1 = precedence_constraint(jobs_ops_map, T, processing_time, alpha)\n",
    "c2 = operation_once_constraint(ops_jobs_map, T, beta)\n",
    "c3 = no_overlap_constraint(T, processing_time, ops_jobs_map, machines_ops_map, gamma)\n",
    "\n",
    "### Objective function\n",
    "c4 = makespan_objective(T, processing_time, jobs_ops_map, len(machines_ops_map), delta)\n",
    "\n",
    "### Combine terms:\n",
    "terms = []\n",
    "terms = c1 + c2 + c3 + c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.quantum.optimization import Problem, ProblemType\n",
    "from azure.quantum.optimization import SimulatedAnnealing # Change this line to match the Azure Quantum Optimization solver type you wish to use\n",
    "\n",
    "# Problem type is PUBO in this instance. You could also have chosen to represent the problem in Ising form.\n",
    "problem = Problem(name=\"Job shop sample\", problem_type=ProblemType.pubo, terms=terms)\n",
    "\n",
    "# Provide details of your workspace, created at the beginning of this tutorial\n",
    "# Provide the name of the solver you wish to use for this problem (as imported above)\n",
    "solver = SimulatedAnnealing(workspace, timeout = 100) # Timeout in seconds\n",
    "\n",
    "# Run job synchronously\n",
    "result = solver.optimize(problem)\n",
    "config = result['configuration']\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit problem to solver\n",
    "job = solver.submit(problem)\n",
    "print(job.id)\n",
    "\n",
    "# Get job status\n",
    "job.refresh()\n",
    "print(job.details.status)\n",
    "\n",
    "# Get results\n",
    "result = job.get_results()\n",
    "config = result['configuration']\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_array(config: dict):\n",
    "    \"\"\"\n",
    "    Create array from returned config dict.\n",
    "\n",
    "    Keyword arguments:\n",
    "    config (dictionary): config returned from solver\n",
    "    \"\"\"\n",
    "\n",
    "    variables = []\n",
    "    for key, val in config.items():\n",
    "        variables.insert(int(key), val)\n",
    "    return variables\n",
    "\n",
    "def print_problem_details(ops_jobs_map:dict, processing_time:dict, machines_ops_map:dict):\n",
    "    \"\"\"\n",
    "\n",
    "    Print problem details e.g. operation runtimes and machine assignments.        \n",
    "\n",
    "    Keyword arguments:\n",
    "    ops_jobs_map (dict): Map of operations to jobs {operation: job}\n",
    "    processing_time (dict): Operation processing times\n",
    "    machines_ops_map(dict): Mapping of machines to operations\n",
    "    \"\"\"\n",
    "\n",
    "    machines = [None] * len(ops_jobs_map)\n",
    "\n",
    "    for m, ops in machines_ops_map.items():\n",
    "        for op in ops:\n",
    "          machines[op] = m\n",
    "\n",
    "    print(f\"           Job ID: {list(ops_jobs_map.values())}\")\n",
    "    print(f\"     Operation ID: {list(ops_jobs_map.keys())}\")\n",
    "    print(f\"Operation runtime: {list(processing_time.values())}\")\n",
    "    print(f\" Assigned machine: {machines}\")\n",
    "    print()\n",
    "\n",
    "def split_array(T:int, array:List[int]):\n",
    "    \"\"\"\n",
    "    Split array into rows representing the rows of our operation matrix.\n",
    "\n",
    "    Keyword arguments:\n",
    "    T (int): Time allowed to complete all operations\n",
    "    array (List[int]): array of x_i,t values generated from config returned by solver\n",
    "    \"\"\"\n",
    "\n",
    "    ops = []\n",
    "    i = 0\n",
    "    while i < len(array):\n",
    "        x = array[i:i+T]\n",
    "        ops.append(x)\n",
    "        i = i + T\n",
    "    return ops\n",
    "\n",
    "def print_matrix(T:int, matrix:List[List[int]]):\n",
    "    \"\"\"\n",
    "    Print final output matrix.        \n",
    "\n",
    "    Keyword arguments:\n",
    "    T (int): Time allowed to complete all operations\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    \"\"\"\n",
    "\n",
    "    labels = \"    t:\"\n",
    "    for t in range(0, T):\n",
    "        labels += f\" {t}\"\n",
    "    print(labels)\n",
    "\n",
    "    idx = 0\n",
    "    for row in matrix:\n",
    "        print(\"x_\" + str(idx) + \",t: \", end=\"\")\n",
    "        print(' '.join(map(str,row)))\n",
    "        idx += 1\n",
    "    print()\n",
    "\n",
    "def extract_start_times(jobs_ops_map:dict, matrix:List[List[int]]):\n",
    "    \"\"\"\n",
    "    Extract operation start times & group them into jobs.\n",
    "\n",
    "    Keyword arguments:\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    \"\"\"\n",
    "    #jobs = {}\n",
    "    jobs = [None] * len(jobs_ops_map)\n",
    "    op_start_times = []\n",
    "    for job, ops in jobs_ops_map.items(): \n",
    "        x = [None] * len(ops)\n",
    "        for i in range(len(ops)):\n",
    "            try :\n",
    "                x[i] = matrix[ops[i]].index(1)\n",
    "                op_start_times.append(matrix[ops[i]].index(1))\n",
    "            except ValueError:\n",
    "                x[i] = -1\n",
    "                op_start_times.append(-1)\n",
    "        jobs[job] = x\n",
    "\n",
    "    return jobs, op_start_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce 1D array of x_i,t = 0, 1 representing when each operation starts\n",
    "op_array = create_op_array(config) \n",
    "\n",
    "# Print config details:\n",
    "print(f\"Config dict:\\n{config}\\n\")\n",
    "print(f\"Config array:\\n{op_array}\\n\")\n",
    "\n",
    "# Print problem setup\n",
    "print_problem_details(ops_jobs_map, processing_time, machines_ops_map)\n",
    "\n",
    "# Print final operation matrix, using the returned config\n",
    "print(\"Operation matrix:\")\n",
    "matrix = split_array(T, op_array) \n",
    "print_matrix(T, matrix)\n",
    "\n",
    "# Find where each operation starts (when x_i,t = 1) and return the start time\n",
    "print(\"Operation start times (grouped into jobs):\")\n",
    "jobs, op_start_times = extract_start_times(jobs_ops_map, matrix)\n",
    "print(jobs)\n",
    "\n",
    "# Calculate makespan (time taken to complete all operations - the objective you are minimizing)\n",
    "op_end_times = [op_start_times[i] + processing_time[i] for i in range(len(op_start_times))]\n",
    "makespan = max(op_end_times)\n",
    "\n",
    "print(f\"\\nMakespan (time taken to complete all operations): {makespan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_precedence(processing_time, jobs):\n",
    "    \"\"\"\n",
    "    Check if the solution violates the precedence constraint.\n",
    "    Returns True if the constraint is violated.\n",
    "\n",
    "    Keyword arguments:\n",
    "    processing_time (dict): Operation processing times\n",
    "    jobs (List[List[int]]): List of operation start times, grouped into jobs\n",
    "    \"\"\"\n",
    "\n",
    "    op_id = 0\n",
    "    for job in jobs:\n",
    "        for i in range(len(job) - 1):\n",
    "            if job[i+1] - job[i] < processing_time[op_id]:\n",
    "                return True\n",
    "            op_id += 1\n",
    "        op_id += 1\n",
    "    return False\n",
    "\n",
    "def check_operation_once(matrix):\n",
    "    \"\"\"\n",
    "    Check if the solution violates the operation once constraint.\n",
    "    Returns True if the constraint is violated.\n",
    "\n",
    "    Keyword arguments:\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    \"\"\"\n",
    "    for x_it_vals in matrix:\n",
    "        if sum(x_it_vals) != 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_no_overlap(op_start_times:list, machines_ops_map:dict, processing_time:dict):\n",
    "    \"\"\"\n",
    "    Check if the solution violates the no overlap constraint.\n",
    "    Returns True if the constraint is violated.\n",
    "\n",
    "    Keyword arguments:\n",
    "    op_start_times (list): Start times for the operations\n",
    "    machines_ops_map(dict): Mapping of machines to operations\n",
    "    processing_time (dict): Operation processing times\n",
    "    \"\"\"\n",
    "    pvals = list(processing_time.values())\n",
    "\n",
    "    # For each machine\n",
    "    for ops in machines_ops_map.values():\n",
    "        machine_start_times = [op_start_times[i] for i in ops]\n",
    "        machine_pvals = [pvals[i] for i in ops]\n",
    "\n",
    "        # Two operations start at the same time on the same machine\n",
    "        if len(machine_start_times) != len(set(machine_start_times)):\n",
    "            return True\n",
    "\n",
    "        # There is overlap in the runtimes of two operations assigned to the same machine\n",
    "        machine_start_times, machine_pvals = zip(*sorted(zip(machine_start_times, machine_pvals)))\n",
    "        for i in range(len(machine_pvals) - 1):\n",
    "            if machine_start_times[i] + machine_pvals[i] > machine_start_times[i+1]:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def validate_solution(matrix:dict, machines_ops_map:dict, processing_time:dict, jobs_ops_map:dict):\n",
    "    \"\"\"\n",
    "    Check that solution has not violated any constraints. \n",
    "    Returns True if the solution is valid.\n",
    "\n",
    "    Keyword arguments:\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    machines_ops_map(dict): Mapping of machines to operations\n",
    "    processing_time (dict): Operation processing times\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    \"\"\"\n",
    "\n",
    "    jobs, op_start_times = extract_start_times(jobs_ops_map, matrix)\n",
    "\n",
    "    # Check if constraints are violated\n",
    "    precedence_violated = check_precedence(processing_time, jobs)\n",
    "    operation_once_violated = check_operation_once(matrix)\n",
    "    no_overlap_violated = check_no_overlap(op_start_times, machines_ops_map, processing_time)\n",
    "\n",
    "    if not precedence_violated and not operation_once_violated and not no_overlap_violated:\n",
    "        print(\"Solution is valid.\\n\")\n",
    "    else:\n",
    "        print(\"Solution not valid. Details:\")\n",
    "        print(f\"\\tPrecedence constraint violated: {precedence_violated}\")\n",
    "        print(f\"\\tOperation once constraint violated: {operation_once_violated}\")\n",
    "        print(f\"\\tNo overlap constraint violated: {no_overlap_violated}\\n\")\n",
    "\n",
    "print_problem_details(ops_jobs_map, processing_time, machines_ops_map)\n",
    "\n",
    "print(\"Azure Quantum solution:\")\n",
    "print_matrix(T, matrix)\n",
    "\n",
    "print(\"Operation start times (grouped into jobs):\")\n",
    "print(jobs)\n",
    "print()\n",
    "\n",
    "validate_solution(matrix, machines_ops_map, processing_time, jobs_ops_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}